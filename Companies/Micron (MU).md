# Micron (MU)

**Category:** Memory
**Est. Price Per Unit:** ~$300-$400 per HBM stack

---

## What They Do

### Product 101 and Where They Fit into the AI Stack
![[Images/mu-hbm4.jpg|300]]

- Micron is an **IDM (integrated device manufacturer)** based in the US. They're part of the memory leaders alongside SK Hynix and Samsung for the HBM used for KV Caches for LLM inference.
- As an IDM, they buy equipment from ASML, Lam Research, etc. and design and manufacture their own chips. These chips are then sent to TSMC or OSATs for packaging.
- Micron is reportedly **sold out in 2026**, recently cancelled their consumer line of 'Crucial' memory cards (gamers are not happy!) to focus on AI data centre memory.

![[Images/MU-memoryPrices.png]]

- Micron sells complete chips, so volume and increasing capacity is critical for their sustained growth.
- Estimated price per stack (one chip) ~$300-$400 for HBM3E; each H100 has 6x of these stacks.
- **80% of Micron's revenue is from DRAM** (HBM fits in here) and **20% is from NAND** (for SSD storage).
- Like all semiconductor companies, the revenue is quite concentrated. The largest customer contributed 17% of FY25 revenue (up from 10%).

### Alignment with Overall Thesis
- As inference continues to grow and context windows increase, the demand for KV Cache HBM memory will continue to expand.
- Currently, it appears that demand for Micron's memory chips is not slowing, as supply shortages are driving pricing higher. The willingness to pay for AI hardware appears as high as ever.

### Business Model, Customers
- Sells complete memory chips (HBM stacks)
- Revenue mix: 80% DRAM / 20% NAND
- Concentrated customer base (largest = 17% of FY25 revenue)

### Comments on Team
- Micron was founded in 1978 and the co-founders are no longer involved.
- The current CEO started in 2017. While he isn't the MU founder, he was a **co-founder of SanDisk in 1988**.
- The Chief Business Officer and EVP of Global Operations followed the CEO to MU.

### Early View of Moat Hypothesis
- Similar to TSMC, years of process optimisation for chip construction is incredibly difficult to replicate.

---

## Why They're Interesting, and Why Now
- Memory is critical for AI inference. Micron is **one of three HBM suppliers** (with SK Hynix and Samsung), and the only US-based option.
- We have to believe that we are in early innings of AI Inference for why now (I believe that we are).

---

## Key Risks
- Demand slows, prices drop, creating a cyclical slowdown.
- Reliance on DRAM HBM slows with next gen of AI methods and chips.

---

## Gaps in Understanding / Key Questions
- Key product and customer differences between SK Hynix. SK Hynix was ahead for HBM, and Samsung is investing heavily for the next wave of HBM, but current state for Micron is unclear.
- Impact of US Chip Act
- Will HBM4 or HBM5 change the landscape or is Micron ready?

---

## Select Financial Graphs

### R1: Total Revenue & YoY Growth
![[Metrics-images/MU-R1-Total-Revenue-YoY-Growth.png]]

### I1: Inventory Turns
![[Metrics-images/MU-I1-Inventory-Turns.png]]

### CF2: FCF Margin
![[Metrics-images/MU-CF2-FCF-Margin.png]]

### V1: EV/Sales NTM
![[Metrics-images/MU-V1-EV-Sales-NTM.png]]

---

## Patent Analysis

### Memory Company Innovation Quality
![[Images/MU-Patent-Innovation-Quality.png]]

### HBM / Stacked Memory: Who Invested Early?
SK Hynix was the HBM pioneer (spike in 2012-2013). Micron started catching up from 2018 onward. Samsung has been a consistent mid-leader since 2009.
![[Images/MU-Patent-HBM-Early-Investment.png]]

### HBM First Mover Advantage
Samsung has the largest total HBM patent portfolio (6,385), but SK Hynix's earlier entry (pioneer spike) translated to current market leadership. Micron (2,591 patents) is building but remains third.
![[Patent analytics/32_hbm_first_mover.png]]

---

## Interesting Topics to Read
- IDM (Integrated Device Manufacturer)
- HBM (High Bandwidth Memory)
